## Collection

### Statistics stuff
- [A resource for experimental psychologists on using R for statistical analyses](https://ademos.people.uic.edu/index.html)
- Basic stats review course w/Python https://www.coursera.org/specializations/data-analysis
- Udacity intro to stats
- OpenIntro Stats
- Statistical Learning Tibrashani Stanford Course (https://lagunita.stanford.edu/dashboard)
	- https://lagunita.stanford.edu/courses/HumanitiesSciences/StatLearning/Winter2016/courseware/995220423fd14a4588d8e47920f1b5df/99faa3a82fca4fc19adc577ce9f75afd/
 - Stanford Statistical Reasoning (Open + Free) https://lagunita.stanford.edu/dashboard
- Stanford Probability and Statistics Probability and Statistics (Open + Free)	https://lagunita.stanford.edu/dashboard
- Probability and stats: python: http://greenteapress.com/thinkstats2/index.html
- watch videos DSS https://www.youtube.com/channel/UCMNZrokQNSm2UQ_T5VfOLgg/videos
- Read https://blog.kapiche.com/four-reasons-sentiment-analysis-is-misinterpreted-4d9bb59b41b9
- https://www.datasciencecentral.com/profiles/blogs/a-simple-introduction-to-complex-stochastic-processes-part-2
- https://www.datasciencecentral.com/profiles/blogs/credit-risk-prediction-using-artificial-neural-network-algorithm
- https://www.datasciencecentral.com/profiles/blogs/5-questions-to-prepare-you-for-your-next-data-science-interview
	https://www.datasciencecentral.com/profiles/blogs/artificial-neural-networks-part1
	
### Linear modelling - complex
- https://bookdown.org/ripberjt/labbook/multivariable-linear-regression.html
- https://bookdown.org/mrwhalen/bayes_book/mcmcglmm.html

### RLadies online tutorials metapage
- From a twitter thread in 2020 for International womens day: [shiny app here](https://yabellini.shinyapps.io/RLadiesLesson/)

### Containers aka Docker etc
- CyVerse workshop materials: https://learning.cyverse.org/projects/cyverse-container-camp/en/latest/docker/dockerintro.html

### R books that use bookdown (freely available online)

- [A ModernDive into R and the tidyverse(Nov 2019](https://moderndive.com/index.html)
  - Has some interesting chapters on basic regression and statistical inference
- [Introduction to Data Science - Tiffany Timbers](https://ubc-dsci.github.io/introduction-to-datascience/index.html)
  - Tidyverse intro plus some basic modelling for prediction
 - [Interpretable Machine Learning](https://christophm.github.io/interpretable-ml-book/)
  - Amazing book on interpretable machine learning methods
 - [Data visualisation by Kieran Heily](https://socviz.co/index.html#preface)
  - Great resource on HOW to properly make plots - a very enjoyable read!
 
### Machine learning
- Course ML course Amazon
- Andrew Ng's Machine Learning course on Coursera (Coursera)
- R based Coursera Johns Hopkins course https://www.coursera.org/specializations/jhudatascience
- Unlock Value in Massive Datasets (spunk course 1) w/ hadoop [ https://www.coursera.org/learn/intro-to-big-data] 
- Spunk .Hadoop. https://www.coursera.org/specializations/big-data
- Data Science and Engineering with Spark - edX berkley - 5 courses starting 14 April. 
- Business metrics (including NOSQL and tableUU intro in later courses) 
	https://www.coursera.org/learn/analytics-business-metrics 
	https://www.coursera.org/specializations/business-analytics
- GIS https://www.coursera.org/specializations/gis
- Data science Harvard see Course Materials note in Evernote
- https://www.coursera.org/specializations/business-analytics
- Udacity nano degree: roll your own  https://www.udacity.com/course/data-analyst-nanodegree--nd002
- IIT web big data python https://www.coursera.org/course/bigdata
	This course is about building 'web-intelligence' applications exploiting big data sources arising social media, mobile devices and sensors, using new big-data platforms based on the 'map-reduce' parallel programming paradigm. In the past, this course has been offered at the Indian Institute of Technology Delhi as well as the Indraprastha Institute of Information Technology Delhi.
- Cal tech Learning from Data http://work.caltech.edu/telecourse
- MIT analytics edge https://www.edx.org/course/analytics-edge-mitx-15-071x-2 /R based/

### Deep learning
	- http://course.fast.ai/lessons/lesson1.html
	- Deep learning in R: https://towardsdatascience.com/how-to-implement-deep-learning-in-r-using-keras-and-tensorflow-82d135ae4889 http://www.rblog.uni-freiburg.de/2017/02/07/deep-learning-in-r/  https://www.datacamp.com/community/tutorials/keras-r-deep-learning
  
### Not free ML books
  - Yet another ML book https://mitpress.mit.edu/books/fundamentals-machine-learning-predictive-data-analytics
  
### Bayesian stuff
- [Doing Bayesian Data Analysis - tidy](https://bookdown.org/content/3686/)
- [This paper](https://link.springer.com/article/10.3758/s13423-016-1221-4)
- [Inspiration: JASP training](https://jasp-stats.org/workshops/)
- [This (long) blog post: Applied Bayesian Statistics Using Stan and R](https://www.mzes.uni-mannheim.de/socialsciencedatalab/article/applied-bayesian-statistics/)
- [The STAN page](https://mc-stan.org/users/documentation/tutorials.html)
- [Applied introduction to Bayesian estimation methods for the uninitiated](https://m-clark.github.io/bayesian-basics/preface.html)
- [An introduction to Bayesian modelling in Stan for economists](https://rpubs.com/jimsavage/stanintro)
- [What people normally cover in a 3 day course](https://statmodeling.stat.columbia.edu/2016/06/28/short-course-on-bayesian-data-analysis-and-stan-19-21-july-in-nyc-2/)

### Time series stuff

- [Forecasting: Principles and Practice](https://otexts.com/fpp2/)
- [Prophet, cool FB algorithm, in R and python](https://facebook.github.io/prophet/)
- [M5 forecasting competition](https://www.kaggle.com/c/m5-forecasting-accuracy)

### Shiny stuff
- [This long blog post](https://www.mzes.uni-mannheim.de/socialsciencedatalab/article/shiny-apps/)

### Data viz
- Berkley visualisation course http://vis.berkeley.edu/courses/cs294-10-sp11/wiki/index.php/CS294-10_Visualization
- ggvis
- vega
- D3js https://www.dashingd3js.com/table-of-contents
- http://openrefine.org/
- http://vis.stanford.edu/wrangler/


### Building a portfolio
- https://www.dataquest.io/blog/data-science-portfolio-machine-learning/
- https://www.dataquest.io/blog/data-science-portfolio-project/
- https://www.upwork.com/hiring/data/15-python-libraries-data-science/


### Other cool R stuff
- [Data science with R: A robust toolkit for psychological research - Danielle Navarro](https://djnavarro.github.io/robust-tools/)
- http://swirlstats.com/students.html
- https://www.coursera.org/specializations/r/

### Python things
- https://github.com/jrjohansson/scientific-python-lectures
- pandas https://github.com/wesm/pydata-book
- https://ep2016.europython.eu/en/events/pydata/
- https://www.youtube.com/user/PyDataTV/videos
- https://github.com/aloctavodia/Statistical-Rethinking-with-Python-and-PyMC3

### CompSci (kind of) stuff
- CSS intro Mozilla https://developer.mozilla.org/en-US/docs/Learn/CSS/Introduction_to_CSS
- CS50X on edX
- R datacamp
- CodeAcademy python, SQL, javascript (others?)
- dive into python
- Algorithmic toolbox coursera
- Once you've gained familiarity with some of these data structures, try your hand at problems on Leetcode.

### Databases

Cassandra, MYSQL, mongoDB, 
Work through Tutorials 1-6 on the SQLzoo website. Feel free to explore the website to be able to complete questions in the tutorials. As a bonus, if you feel comfortable with the SQL on the SQLzoo website, try to work through the SQL homework questions on the Databases course on Coursera. If you want to start a data project using MySQL and Python, follow Zetcode's tutorial to learn to interface with MySQL through Python.
Work through the "basic" and "intermediate" lessons at Mode Analytics' SQL School. Insight Fellows love this site because it includes a nice platform for testing your queries on real databases in your browser!
Practice connecting Python to MySQL or Postgres. Fellows from our previous sessions told us this piece was particularly helpful for building projects.

- Stanford databases course Introduction to Databases https://lagunita.stanford.edu/dashboard
- Sql school https://sqlschool.modeanalytics.com/
- MongoDB
- SQLzoo
- SQLalchemy http://www.rmunn.com/sqlalchemy-tutorial/tutorial.html
- datamonkey.pro

### Math
- Khan linear algebra followed by Multivariate calculus followed by linear algebra from MIT (14+14 weeks = 6 months)
- Linear algebra (math track) Khan Academy https://www.khanacademy.org/math/linear-algebra
- Linear algebra MIT open courseware
Linear algebra http://web.mit.edu/18.06/www/videos.shtml
http://www.ulaff.net/
	http://codingthematrix.com/
		Life Sciences edX track also has a linear algebra course
http://www.engineering.iastate.edu/~julied/classes/CE570/Notes/strangpaper.pdf


### Big data 
	- http://ampcamp.berkeley.edu/big-data-mini-course/
	- Hadoop https://www.udacity.com/course/intro-to-hadoop-and-mapreduce--ud617 https://developer.yahoo.com/hadoop/tutorial/
		open source framework for for storage and large-scale processing of datasets on clusters of commodity hardware
	- MapReduce
		programming paradigm that allows for massive scalability across the servers in a hadoop cluster
	- Spark https://www.edx.org/xseries/data-science-engineering-spark @whenoffered @next
		Hadoop's speedy swiss army knife  - fast running data analysis system that provides real time processing functions to Hadoop


### Other things

- https://www.youtube.com/playlist?list=PLYx7XA2nY5Gf37zYZMw6OqGFRPjB1jCy6

### Kaggle advice
- I would NOT recommend doing any of the prize-money competitions. They usually have datasets that are too large, complicated, or annoying, and are not good for learning (Kaggle.com)
- Start by learning scikit-learn, playing around, reading through tutorials and forums at https://www.kaggle.com/c/data-science-london-scikit-learn/rules?returnUrl=%2Fc%2Fdata-science-london-scikit-learn%2Fsubmit for a simple, synthetic, binary classification task. Next, play around some more and check out the tutorials for Titanic: Machine Learning from Disaster https://www.kaggle.com/c/titanic-gettingStarted with a slightly more complicated binary classificationtask (with categorical variables, missing values, etc.)
- Afterwards, try some multi-class classification with Forest Cover Type Prediction https://www.kaggle.com/c/forest-cover-type-prediction. Now, try a regression task Bike Sharing Demand that involves incorporating timestamps https://www.kaggle.com/c/bike-sharing-demand. Try out some natural language processing withSentiment Analysis on Movie Reviews. https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews Finally, try out any of the other knowledge-based competitions that interest you!

### Online courses register (aka other people's workshops)
#### Using R
- [Data Science for ecologists and environmental scientists](https://ourcodingclub.github.io/course)

***
# Books
- Introduction to Econometrics (3rd Edition) (Addison-Wesley Series in Economics) 3rd Edition by James H. Stock  (Author), Mark W. Watson (Author)
- Quinn Keogh Experimental design and data analysis for biology
- http://cs231n.github.io/
- Applied Predictive Modeling 2013th Edition by Max Kuhn  (Author), Kjell Johnson  (Author)

Coding:
	- Google Python course
		Up to Python Dict and File & Exercise: wordcount.py
		This is a free class for people with a little bit of programming experience who want to learn Python. The class includes written materials, lecture videos, and lots of code exercises to practice Python coding. These materials are used within Google to introduce Python to people who have just a little programming experience.
	- Python Language Essentials
	- http://interactivepython.org/runestone/static/pythonds/index.html Code the examples in Problem Solving with Algorithms and Data Structures in Python. In particular, become familiar with stacks, queues, linked lists, merge sort, quick sort, and searching and hashing. If you prefer to learn by watching lectures, check out the MIT Introduction to Algorithms course. Bonus: For each algorithm or data structure you learn about, try to program it from scratch in Python, from memory. Many Fellows have also found Leetcode to also be useful in the interview prep for their CS section.- Focus on gaining familiarity with stacks, queues, linked lists, sorting algorithms, and searching and hashing.
	- Python for Data Analysis Data Wrangling with Pandas, NumPy, and IPython By Wes McKinney 
		This 50 page appendix to 'Python for Data Analysis' is not intended to be an exhaustive introduction to the Python language but rather a biased, no-frills overview of features which are used repeatedly in Data Science projects. For new Python programmers, it is recommended that you supplement this with the official Python tutorial and potentially one of the many excellent (and much longer) books on general purpose Python programming.
		- https://github.com/estimate/pandas-exercises
	- Up until Codecademy's exam statistics unit (Codecademy has an excellent python course that only takes an estimated 13 hours to complete.)
		-CodeAcademy is a free website with tutorials to teach users rudimentary programming. Its Python course is aimed at non-programmers and will slowly take you through various programming concepts. The course is split up in teaching and practice units so you'll also learn why certain techniques are useful. Remember that Codecademy also provides an excellent glossaryof concepts and techniques you'll likely employ in your adventures.
	- Python practice book
		-Chapters 1. Getting Started and 2. Working with Data, also read A Plan for Spam by Paul Graham which describes a method of detecting spam using probability of occurrence of a word in spam.
		This book is prepared from the training notes of Anand Chitipothu. Good presentation, stays on topic with lot's of little excercises to check comprehension.
		http://anandology.com/python-practice-book/getting-started.html
		http://paulgraham.com/spam.html
	- Zed Shaw's excellent Learn Python the Hard Way.
	- Hardcode: Computer science coding interviews book (2 months): Elements of Programming Interviews
		I assume that you have taken an algorithms course and know your way around major data structures including but not limited to: binary trees, binary search trees, hash tables, heaps, stacks, queues, graphs, lists, tries... as well as all algorithms related to them (insert, delete, search, find, find max, find min...) and the time complexity for each of these, at least at a high level. For graphs you need to know searches (BFS and its properties, DFS and its properties including cycle detection and the like) and shortest path algorithms (Dijkstra, Bellman-Ford, and A*) at a bare minimum. If you don't know all these, along with Dynamic Programming, you're going to need longer than a month. Pick up Introduction to Algorithms (CLRS) and start studying them first. (Update: I posted an answer here: Jimmy Saade's answer to What should I know from CLRS 3rd edition book if my aim is to get into Google? in regards to which parts of CLRS are relevant for technical interviews.) This is the easy part, as it's all academic and it's just expected that you know all of it. The part that follows below (Day 1 onwards) is the actually valuable part that I can offer you.
		I also assume that you know a programming language like C++ (or Java) and the built-in functions which actually make it useful (i.e. STL or its Java equivalents). (Update 2: I posted info relevant to this here: Jimmy Saade's answer to What are the most important concepts in C and C++ that should be learnt and understood before a programming interview?). If you don't know STL, spend time learning vectors, maps, sets, unordered maps, unordered sets, queues, stacks, and the entire "algorithm" library (seriously, all of it). These are essentially implementations of what you just learned in CLRS, so that if you need to use a heap you won't actually start to code one during an interview (just use a map or priority queue). You also need to know how to implement a linked list, BST, and a trie in 5 minutes flat, which is a lot easier than it sounds (just build a Node class and an insert function and for interview purposes, you're good.)
		In all seriousness, this is the best book on the subject in my opinion, and I'm actually really surprised so little people know about it or use it. The collection of questions is excellent and to-the-point, it is large (300+ problems, which is the most I've seen in one book), they focus on the right concepts (e.g. several problems are on binary search, which is extremelylikely to come up in an interview - more so than any other algorithm), and their answers (and the code provided) are almost all correct and excellent. I say "almost" because there are 1 or 2 problems which have much simpler solutions than the book details, but it's not an issue, especially when you compare it with other programming interview books, which have several answers which are downright incorrect. Plus the online support community is pretty good, with Java code available for all problems (the book has them in C++ only) and an online forum for discussions over at Home - Elements of Programming Interviews. They also forgo all the 'teaching' stuff that other books have where they try to teach you big-O notation and data structures, and focus almost completely on the problems part, which is much, much, much, much more important. The big-O notation and data structures you should learn from CLRS, which is the best resource for them, period. No other book, especially not programming interview books, come close to its quality in teaching that stuff.
		Days 2-14 - Algorithms Stage
			Go through the book chapter by chapter, one chapter per day[1], starting at Chapter 5, ending at Chapter 19. Do every single problem. All of them. (To be completely honest, I might've skipped a few, but this was more by accident than anything else, and I definitely did like 98%+ of them.) Don't code, solve the problems only (i.e. find the algorithm). Give yourself a deadline per problem, depending on how hard the problem is (for example, 10 minutes for non-ninja[2] problems, 20 minutes for gray-ninja problems, 30-40 minutes for black-ninja problems) - if you haven't found the solution by then, look at the answer and understand it. If you don't you won't improve. It's important to think of the problems on your own, because it's the way of thinking that matters, as you can't go and recite the book on interview day. If you found a solution, make sure it's correct, and that you have thought of all corner cases.
				Note 1: The new version of the book (which I linked to) has all the ninja problems in a separate chapter (Ch. 22). This, in my opinion, is a terrible idea. The book I had had the problems which are currently in Ch. 22 spread across the book, each in its relevant chapter. I suggest you go through the relevant ninja problems of each chapter while doing said chapter. For example, on Day 2, do Chapter 5, and the Chapter 5-related problems in Chapter 22. On Day 3, do Chapter 6, and the Chapter 6-related problems in Chapter 22, and so on. I believe the problems in Ch. 22 are ordered accordingly (the ninja problems of Ch. 5 come first, then those of Ch. 6, and so on), so this shouldn't be too hard, but I'm not 100% sure as I have the older copy of the book.
				Note 2: I sometimes spent hours on a single problem, just because I thought the problem was really interesting and I insisted on cracking it myself. I find these random endeavours useful in the long run, as it develops your critical thinking a lot more than the easier problems, but it also takes time, so you likely can't do this for every problem, if you even want to do it at all.
		Days 14-24 - Coding Stage
			Repeat the book, this time with coding. You already know the answers, so you should be able to remember the algorithm for each problem pretty quickly (if you don't, look it up. It happens, and it can happen sometimes even if you'd previously figured the problem out by yourself.) This is the coding stage, so don't waste time re-deriving algorithms.
			I do not suggest you code all problems, especially if you're experienced with ACM-ICPC, TopCoder, or Codeforces and the like (and really, if you're familiar enough with STL, you probably have a decent skill set). Only write the code for problems you feel have complex algorithms, a new data structure you haven't used before (e.g. unordered map for hashing maybe), problems with tricky corner cases (binary search is at the top of this list as its variants are asked often and can be much trickier than you think) or a programming concept you're not comfortable with (these include, but are not limited to, operator overloading, custom comparators, custom hash functions, custom == functions, and much more...) If a problem proves tricky for you, or you implemented it in a way which you feel isn't optimal, look at the solutions the book provides, which are excellent and clean, and will teach you all of the above-mentioned concepts. I suggest you mimic their style of writing code a bit. Some important-if-obvious notes are: use descriptive variable names (none of that 1-letter-variable-name crap) and indent properly, and don't forget to close parentheses and brackets.
			I also suggest you code all problems from the Greedy Algorithms chapter and almost all ninja-marked problems. The Dynamic Programming chapter is also important if you're not familiar with DP, and can be tough to grasp, so make sure you give it its time.
		- R inferno
Databases:
	- - Work through the "basic" and "intermediate" lessons at Mode Analytics' SQL School (https://sqlschool.modeanalytics.com/). Insight Fellows love this site because it includes a nice platform for testing your queries on real databases in your browser!
	- Practice connecting Python to MySQL or Postgres. Fellows from our previous sessions told us this piece was particularly helpful for building projects. (http://zetcode.com/db/mysqlpython/) (http://zetcode.com/db/postgresqlpythontutorial/)
	- If you have more time, check out this tutorial on SQLAlchemy, an increasingly popular Python module that allows you to access and modify SQL databases in a more "pythonic" way. (http://www.rmunn.com/sqlalchemy-tutorial/tutorial.html)
	- O'Reilley's SQL Cookbook is a masterpiece that traverses all levels of SQL proficiency.
Statistics:
	- Think Stats is an introduction to Probability and Statistics for people who have some exposure to python http://www.greenteapress.com/thinkstats/
	- Statistics in a Nutshell is a clear and concise introduction and reference for anyone new to the subject, and especially those who want to apply this powerful tool to real problems, this is a most useful book. Perhapps not so much an introduction to statistics but rather as a tool for those who know there is a procedure that will really help them solve a present problem, but can't remember what it was nor exactly how to use it.
	- Charles Wheelan's Naked Statistics is an insightful book laced with college-style humor as indicated by the soft porn book cover. Read this book if you want to understand the concepts behind statistics without having to mine a text book. The book is a quick read at only 250 pages, much of it skimmable. It is especially valuable for digital analytics professionals and marketing executives who want to understand more about data science predictions which are essentially statistically-based "guesstimates".
	- Sample items from Metacademy's Learning Plan. Probability and Random Variables are prerequisite topics prior to picking up Expectation and Variance. Review as is necessary for your level of understanding.
		-Metacademy is built around an interconnected web of concepts, each one annotated with a short description, a set of learning goals, a (very rough) time estimate, and pointers to learning resources. The concepts are arranged in a prerequisite graph, which is used to generate a learning plan for a concept. It's pretty fantastic, and a much more elaborate implementation of the idea this checklist was built on.

Pandas:
	- Pandas cookbook
		A quick tour of the IPython Notebook - Shows off IPython's awesome tab completion and magic functions.
		Reading from a CSV - Reading your data into pandas is pretty much the easiest thing. Even when the encoding is wrong!
		Selecting data - It's not totally obvious how to select data from a pandas dataframe. Here I explain the basics (how to take slices and get columns)
		More selecting data - Here we get into serious slicing and dicing and learn how to filter dataframes in complicated ways, really fast.
		groupby and aggregate - The groupby/aggregate is seriously my favorite thing about pandas and I use it all the time. You should probably read this.
		The goal of this cookbook is to give you some concrete examples for getting started with pandas. The docs are really comprehensive. However, I've often had people tell me that they have some trouble getting started, so these are examples with real-world data, and all the bugs and weirdness that that entails.
	- Learn Pandas
		A series of simple notebooks showcasing how to do data analysis with pandas based on a motivating examples of finding baby name popularity and customer counts.
		- Babynames
		- Babynames Redux
		- Customer Data
		- Back to Basics
		- Stack & Unstack
		- Groupby
	- Python for Data Analysis is concerned with the nuts and bolts of manipulating, processing, cleaning, and crunching data in Python. It is also a practical, modern introduction to scientific computing in Python, tailored for data-intensive applications. This is a book about the parts of the Python language and libraries you’ll need to effectively solve a broad set of data analysis problems.
	- Use the Exercises devised by Wes M. https://github.com/estimate/pandas-exercises
	- https://github.com/jakevdp/sklearn_scipy2013
	- https://github.com/fonnesbeck/statistical-analysis-python-tutorial

Maths:

Machine learning:
	- P.-N. Tan, M. Steinbach, and V. Kumar. Introduction to Data Mining, (First Edition). Addison-Wesley Longman Publishing Co., Inc., Boston, MA, USA, 2005.
	- Python Machine learning: I don't want to self-advertise here, but I think my book would be a good follow-up to learn ML in more depth, understand the algorithms, learn about different data processing pipelines and evaluation techniques, best practices, and learn how to put in into action using Python, NumPy, scikit-learn, and Theano so that you can start working on your personal projects.
	- Building Machine Learning system with Python shows you exactly how to find patterns through raw data. The book starts by brushing up on your Python ML knowledge and introducing libraries, and then moves on to more serious projects on datasets, Modelling, Recommendations, improving recommendations through examples and sailing through sound and image processing in detail.
	- T. Hastie, R. Tibshirani, J. Friedman, T. Hastie, J. Friedman, and R. Tibshirani. data mining, inference, and prediction. 2nd Edition., volume 2. Springer, 2009.
	- C. M. Bishop et al. Pattern Recognition and Machine Learning | Christopher Bishop | Springer, volume 1. springer New York, 2006.
	- Duda, Richard O., Peter E. Hart, and David G. Stork. Pattern Classification, 2nd Edition. John Wiley & Sons, 2012.
	- the Deep Learning book (Page on iro.umontreal.ca) by Yoshua Bengio, Ian Goodfellow, and Aaron Courville. The release date is set around 2016, but the 613-page manuscript is already available as as of today (online and for free).
	- - For a broader-audience view on the machine learning field, I recommend The Master Algorithm by Pedro Domingos.
	- For a broad, highly technical perspective on the main ML topics, I recommendMachine Learning, A Probabilistic Perspective by Kevin P. Murphy
	- For those interested in graphical models, I recommend Probabilistic Graphical Models: Principles and Techniques by Daphne Koller and Nir Friedman
	- Applied Predictive Modeling by Kuhn and Johnson. Although it is written for R users, it provides a clearly written and excellent overview of the various machine learning models and how they fit together.
  
  
***
Harvard DS masters course list:
	at least three of the four core courses.
	at least one Applied Math elective and one Computer Science elective chosen from the suggested electives list.
	up to two “domain electives”—approved courses within a domain of study. If two domain electives are included in the plan of study at least one of them must be computation-intensive.
	up to one semester-length independent research project.
	up to one semester of the  capstone project course.
	up to one semester of the AC 298r seminar course.
	
	Core courses:
		Applied Math 205 - Advanced Scientific Computing: Numerical Methods:
			Christopher Rycroft, Assistant Professor. Fall Term, Tues/Thurs 10:00 - 11:30 AM.
			An examination of the mathematical foundations of a range of well-established numerical algorithms, exploring their use through practical examples drawn from a range of scientific and engineering disciplines. Emphasizes theory and numerical analysis to elucidate the concepts that underpin each algorithm. There will be a significant programming component. Students will be expected to implement a range of numerical methods through individual and group-based project work to get hands-on experience with modern scientific computing.
			http://iacs-courses.seas.harvard.edu/courses/am205/
			- Textbook: Scientific Computing: An Introductory Survey, by Michael T. Heath.
			
		Applied Math 207 - Advanced Scientific Computing: Stochastic Methods for Data Analysis, Inference and Optimization:
			AM207 Stochastic Methods for Data Analysis, Inference and Optimization
			Rahul Dave, Lecturer. Spring Term, Tues/Thurs 11:30 AM - 1:00 PM.
			Develops skills for computational research with focus on stochastic approaches, emphasizing implementation and examples. Stochastic methods make it feasible to tackle very diverse problems when the solution space is too large to explore systematically, or when microscopic rules are known, but not the macroscopic behavior of a complex system. Methods will be illustrated with examples from a wide variety of fields, like biology, finance, and physics.
			Monte Carlo methods are a diverse class of algorithms that rely on repeated random sampling to compute the solution to problems whose solution space is too large to explore systematically or whose systemic behavior is too complex to model. This course introduces important principles of Monte Carlo techniques and demonstrates the power of these techniques with simple (but very useful) applications. Starting from the basic ideas of Bayesian analysis and Markov chain Monte Carlo samplers, we move to more recent developments such as slice sampling, multi-grid Monte Carlo, Hamiltonian Monte Carlo, parallel tempering and multi-nested methods. We complete our investigation of Monte Carlo samplers with streaming methods such as particle filters/sequential Monte Carlo. Throughout the course we delve into related topics in stochastic optimization and inference such as genetic algorithms, simulated annealing, probabilistic Gaussian models, and Gaussian processes. Applications to Bayesian inference and machine learning are used throughout. We will be using Python for all programming assignments and projects. All lectures will be recorded and should be available 24 hours after meeting time.
			
			Overall the course consists of the following modules
			Introduction to basic monte carlo methods: Buffon's needle, pi estimation, rejection and importance sampling, variance reduction methods;
			Bayes formalism and sampling: Bayesian modeling, Markov Chains, Metropolis-Hastings, MCMC convergence analysis, hierarchical Bayes, Gibbs sampling;
			Stochastic Optimization: simulated annealing, stochastic gradient decent, genetric algorithms;
			Dynamic systems: time series analysis, autoregressive-moving-average model, Box-Jenkins method, hidden Markov model, Sequential Monte Carlo, Particle Filters, Gaussian Processes;
			Advanced sampling methods: slice sampling, Hamiltonian MC, Parallel Tempering, Emcee
			Graphical Models: Basic modeling assumptions, learning graphical models
			
			Why take this class? MCMC methods enable you to tackle multi-dimensional integrals, and thus are a key concept in Bayesian statistics, and computational sciences. Do you know the unsatisfactory feeling that a non-conjugate prior would actually better model your application, but you don't know how to handle the complicated resulting posterior? After this course this will be no problem anymore. Feeling stuck with estimating complex scenarios like neutron diffusion or the interaction of an electron beam with a biological sample? With MCMC you will save tons of paper and living trees by using stochastic simulation instead of pages over pages of numerical derivations. Also, stochastic optimization is widely used for optimizing highly non-convex loss functions, like they arise in training deep neural networks.
			
			Book recommendations
			Please note there there is no required textbook for this course. The following list has some recommendations in case you are eager to learn more, or would like to see the material presented in a different way
			Machine Learning: a Probabilistic Perspective by Kevin Patrick Murphy
			Bayesian Data Analysis by Andrew Gelman et al.
			Monte Carlo Streategies in Scientific Computing by Jun S. Liu (available as download via Harvard Library)
			Monte Carlo Statistical Methods by Christian P. Robert and George Casella (available as download via Harvard Library)
		CS205: Computing Foundations for Computational Science:
			Students are expected to have basic programming experience (e.g., CS 50). Familiarity with Python is strongly recommended.
			This is an applications course highlighting the use of modern computer architectures in solving scientific problems. The class emphasizes making effective use of modern architectures, particularly parallel, multicore, and GPU-based processing, with a strong emphasis on "parallel thinking." You will learn the fundamentals of scientific computing including abstract thinking, algorithmic development, and assessment of computational approaches, using a series of open source tools and libraries for data analysis, modeling, and visualization of real scientific problems.
			After taking this course, you should be able to:
			Apply basic computer science concepts such as modularity, abstraction, and encapsulation to scientific problems,
			Apply concepts of parallel programming and “parallel thinking” to computational science
			Recognize and recall computer architectures, algorithms, and data structures that are relevant to computational science,
			Analyze and visualize large scientific data and implement data-intensive computations on cluster and cloud infrastructures,
			Use open-source tools for large- and fine-grain parallel computations, cloud computing, and visualization.
			Recommended Textbooks:
			Introduction to parallel computing 
			Ananth Grama, Anshul Gupta, George Karypis, Vipin Kumar
			Programming Massively Parallel Processors: A Hands-on Approach 
			David B. Kirk and Wen-mei W. Hwu
			Patterns for Parallel Programming 
			Timothy G. Mattson, Beverly A. Sanders, Berna L. Massingill
			The Art of Multiprocessor Programming 
			Maurice Herlihy and Nir Shavit
			Safari Books Online at Harvard
			
		CS 207: Systems Development for Computational Science:
			The prerequisite for this class is programming knowledge, in Python, at the level of CS50 and CS 109 (or above). Besides this, you should have interest or investment in scientific computing.
			Use Python, including its advanced features to write scientific programs
			
			understand what features of Python (or for that matter any programming language) make up its language execution model and how these features impact the code you write: e.g. how modularity, abstraction, and encapsulation can be used to solve problems
			
			write these programs with good software engineering practices
			
			code data management techniques to store data, staring from a good understanding of data structures.
			
			combine these techniques together to write large pieces of software (you will do a group project for this), working in a team of scientists, programmers, etc.
			
			Be able to hit the road running as a scientist in a startup or other company, or for that matter in academia: you will be able to evaluate and test software to see which one your group ought to use. You will also be a capable unicorn: able to contribute on both the science and software engineering sides of things.
			
			
			No book is required. But we highly recommend two books for this course.
			
			Fluent Python: Clear, Concise, and Effective Programming, by Luciano Ramalho. Publisher: O'Reilly Media. 2015.
			Designing Data Intensive Applications, by http://dataintensive.net/, The Big Ideas Behind Reliable, Scalable, and Maintainable Systems by Martin Kleppmann. Publisher: O'Reilly Media 2014
			
			The Practice of Programming (ISBN 0-201-61586-X) by Brian W. Kernighan and Rob Pike, Addison-Wesley, 1999.
			Skiena: The Algorithm Design Manual
			Abelson, Sussmann and Sussmann: SICP and python based online version based on it: http://composingprograms.com/
			High Performance Python: By Micha Gorelick, Ian Ozsvald. Oreilly Media 2014.
			Hacker guide to python testing sample chapter (book's pretty good too) (https://julien.danjou.info/media/the-hacker-guide-to-python-sample.pdf)
			
			What are the expectations for the final project?
			
			There are 3 database like systems in this project: The Storage manager and associated SMTimeSeries, the postgres database with metadata, and the socket server fronted red-black tree based Vantage Point database. All 3 of these talk to the REST HTTP server, which in turn is fronted by the web UI. The latter is not complete, but with just enough implementation to give you the experience of making a Web UI. Setting up the whole stack is a skill which will be very useful in your career.
			The Timeseries and Storage Manager parts should be usable independent of the rest of the system and should be python setup.py install installable. You dont have to make a direct-from-PyPI installable project, but the user ought to be able to download the module, do python setup.py test, see docs by doing python setup.py docs, and install by doing python setup.py install. (You could also use pip (not frpm PyPI), in which case make it directly installable from your github repo. (For this you'll have to separate the module out into its own github repo))
			Ditto for the code for the red-black tree. (I dont mean here the server, or the command line program, I mean just the red-black tree with floating point keys and ids as values). The command line program and server ought to use this as a module
			Thats all for modules for us.
			The rest of the project should be automatically installable on AWS using a bash script to be run on the AWS machine; including all the python, postgres, nginx, etc provisioning after you have chosen an ubuntu image.
			We will follow your instructions to run and test your code. Where possible use appropriate technologies in this install script, such as pip -r requeirements.txt and so on and so forth. The web page should show up at the DNS address that Amazon gives you.
			Documentation for every subsystem in the project should be provided. If needed, generate using PyScaffold. Link to the docs from the README.md in each folder. The top level README.md should contain an overview, links to other docs, and an installation guide which will help us install and test your system.
			For those parts of the project which are modules, python setup.py test should suffice. For all other parts, include instructions on how to test your code. Where possible, provide links to Travis-CI test runs and Coveralls coverage.
	
	Applied Math elective:
		Computer Science 109a/Applied Computation 209a/Statistics 121a Data Science 1: Introduction to Data Science:
		https://canvas.harvard.edu/courses/12656/assignments/syllabus
		Data Science 1 is the first half of a one-year introduction to data science. The course will focus on the analysis of messy, real life data to perform predictions using statistical and machine learning methods. Material covered will integrate the five key facets of an investigation using data: (1) data collection - data wrangling, cleaning, and sampling to get a suitable data set;  (2) data management - accessing data quickly and reliably; (3) exploratory data analysis – generating hypotheses and building intuition; (4) prediction or statistical learning; and (5) communication – summarizing results through visualization, stories, and interpretable summaries. Note: Only one of CS 109a, AC 209a, or Stat 121a can be taken for credit. Students who have previously taken CS 109, AC 209, or Stat 121 cannot take CS 109a, AC 209a, or Stat 121a for credit. Programming knowledge at the level of CS 50 or above, and statistics knowledge at the level of Stat 100 or above (Stat 110 recommended).
		
		Applied Computation 209b - Data Science 2: Advanced Topics in Data Science:
		Data Science 2 is the second half of a one-year introduction to data science. Building upon the material in Data Science 1, the course introduces advanced methods for data wrangling, data visualization, and statistical modeling and prediction. Topics include big data and database management, interactive visualizations, nonlinear statistical models, and deep learning. Note: Can only be taken after successful completion of CS 109a, AC 209a, Stat 121a, or equivalent. Students who have previously taken CS 109, AC 209, or Stat 121 cannot take CS 109b, AC 209b, or Stat 121b for credit. CS 109a, AC 209a, or Stat 121a required
	CS elective:
	
	Two core courses:
	
	AC 297r:
	http://iacs.seas.harvard.edu/student-research-projects
	The CSE capstone project is intended to integrate and apply the skills and ideas CSE students acquire in their core courses and electives. By requiring students to complete a substantial and challenging collaborative project, the capstone course will prepare students for the professional world and ensure that they are trained to conduct research. There will be no homework or lectures. Students will be dealing with real-world problems, messy data sets, and the chance to work on an end-to-end solution to a problem using computational methods.
	
	
	
	AC 297s:
	This course, centered on the Institute for Applied Computation Science (IACS) seminar series, will provide broad exposure to cutting-edge topics, applications, and unifying concepts in Computational Science & Engineering. Students will read, present and discuss journal articles related to IACS talks, attend the seminars and meet with visiting speakers. Possible topics to be covered include scientific visualization, computational approaches to disease, mathematical neuroscience, computational archeology, and computational finance.
	http://www.seas.harvard.edu/programs/graduate/computational-science-and-engineering/2014-2015-iacs-seminars
	Videos ongoing and available online! FREE

